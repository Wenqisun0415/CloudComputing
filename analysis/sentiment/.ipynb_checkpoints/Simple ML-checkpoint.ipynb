{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Traditional Machine Learning Methods For Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages / modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peiyuns/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/peiyuns/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"twitter_samples\")\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji\n",
    "from nltk.tokenize.casual import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read positive and negative tweets\n",
    "positive_tweets = twitter_samples.strings(\"positive_tweets.json\")\n",
    "negative_tweets = twitter_samples.strings(\"negative_tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "vec = DictVectorizer()  # Vectorizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_hashtag(hashtag):\n",
    "    i = 0\n",
    "    while(hashtag[i] == \"#\"):\n",
    "        i += 1\n",
    "        if i == len(hashtag):\n",
    "            return -1\n",
    "    \n",
    "    # multiple hashtags in the word\n",
    "    if \"#\" in hashtag[i:]:\n",
    "        return -1\n",
    "    \n",
    "    return hashtag[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_symbols = [\":)\", \":(\", \":D\", \":-)\", \":p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweets):\n",
    "    new_tweets = []\n",
    "    for tweet in tweets:\n",
    "        new_tweet = []\n",
    "        for word in tokenizer.tokenize(tweet):\n",
    "            \n",
    "#             # lowercase\n",
    "#             word = word.lower()\n",
    "            \n",
    "            # regular words\n",
    "            if not (word in stop_words or re.search(\"[^a-zA-Z]\",word)):  # if not stopwords and non-alphabetic\n",
    "                new_tweet.append(lemmatizer.lemmatize(word))\n",
    "            \n",
    "            # hashtags\n",
    "            elif word[0] == \"#\":  \n",
    "                hashtag = handle_hashtag(word)\n",
    "                if hashtag != -1:\n",
    "                    new_tweet.append(\"#\" + lemmatizer.lemmatize(hashtag))\n",
    "            \n",
    "            # symbols / emojis\n",
    "            elif word in frequent_symbols or word in emoji.UNICODE_EMOJI:\n",
    "                new_tweet.append(word)\n",
    "                \n",
    "        new_tweets.append(new_tweet)\n",
    "    \n",
    "    # split into training, development, and testing\n",
    "    training, develop_test = train_test_split(new_tweets, test_size=0.2)\n",
    "    development, testing = train_test_split(develop_test, test_size=0.5)   \n",
    "    \n",
    "    return (training, development, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Excluding hashtags containing stop words and non-alphabetic chars\n",
    "(positive_training, positive_develop, positive_test)  = preprocess(positive_tweets)\n",
    "(negative_training, negative_develop, negative_test)  = preprocess(negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get array of dictionary according to the list of tweets \n",
    "def getDict(tweets):\n",
    "    dict_arr = []\n",
    "    for tweet in tweets:\n",
    "        tweet_dict = {}\n",
    "        for word in tweet:\n",
    "            if word in tweet_dict:\n",
    "                tweet_dict[word] += 1\n",
    "            else:\n",
    "                tweet_dict[word] = 1\n",
    "        dict_arr.append(tweet_dict)\n",
    "    return dict_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, development, testing sets and targets\n",
    "X_train = vec.fit_transform(getDict(positive_training + negative_training))\n",
    "y_train = len(positive_training)*[1] + len(negative_training)*[0]\n",
    "\n",
    "X_dev = vec.transform(getDict(positive_develop + negative_develop))\n",
    "y_dev = len(positive_develop)*[1] + len(negative_develop)*[0]\n",
    "\n",
    "X_test = vec.transform(getDict(positive_test + negative_test))\n",
    "y_test = len(positive_test)*[1] + len(negative_test)*[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes hyperparameters:\n",
      "alpha =   0.001, Score = 0.9510\n",
      "alpha =   0.010, Score = 0.9670\n",
      "alpha =   0.100, Score = 0.9830\n",
      "alpha =   1.000, Score = 0.9860\n",
      "alpha =  10.000, Score = 0.9830\n",
      "alpha = 100.000, Score = 0.9810\n",
      "\n",
      "Logistic Regression hyperparameters\n",
      "penalty = l1, C =    0.001, Score = 0.8600\n",
      "penalty = l2, C =    0.001, Score = 0.9550\n",
      "penalty = l1, C =    0.010, Score = 0.9850\n",
      "penalty = l2, C =    0.010, Score = 0.9560\n",
      "penalty = l1, C =    0.100, Score = 0.9960\n",
      "penalty = l2, C =    0.100, Score = 0.9960\n",
      "penalty = l1, C =    1.000, Score = 0.9960\n",
      "penalty = l2, C =    1.000, Score = 0.9960\n",
      "penalty = l1, C =   10.000, Score = 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peiyuns/anaconda2/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty = l2, C =   10.000, Score = 0.9960\n",
      "penalty = l1, C =  100.000, Score = 0.9960\n",
      "penalty = l2, C =  100.000, Score = 0.9960\n",
      "penalty = l1, C = 1000.000, Score = 0.9960\n",
      "penalty = l2, C = 1000.000, Score = 0.9960\n",
      "\n",
      "Naive Bayes: best parameter: {'alpha': 1}, score = 0.986000\n",
      "Logistic Regression: best parameter: {'C': 0.1, 'penalty': 'l1'}, score = 0.996000\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter sets\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "penaltys = ['l1', 'l2']\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "# Init best hyperparameters\n",
    "best_bayes_params = {}\n",
    "best_bayes_score = 0\n",
    "best_logistic_params = {}\n",
    "best_logistic_score = 0\n",
    "\n",
    "print(\"Naive Bayes hyperparameters:\")\n",
    "# Tune naive bayes hyperparameters\n",
    "for alpha in alphas:\n",
    "    bayes = MultinomialNB(alpha = alpha) # Create classifier\n",
    "    bayes.fit(X_train, y_train) # Train model\n",
    "    score = bayes.score(X_dev, y_dev) # Calculate score \n",
    "    print (\"alpha = %7.3f, Score = %.4f\" % (alpha, score)) # Print result\n",
    "    \n",
    "    # Check if better\n",
    "    if score > best_bayes_score:\n",
    "        best_bayes_params = {'alpha':alpha}\n",
    "        best_bayes_score = score\n",
    "\n",
    "print(\"\\nLogistic Regression hyperparameters\")\n",
    "# Tune logistic regression hyperparameters\n",
    "for C in Cs:\n",
    "    for penalty in penaltys:\n",
    "        logistic = LogisticRegression(C = C, penalty = penalty) # Create classifier\n",
    "        logistic.fit(X_train, y_train) # Train model\n",
    "        score = logistic.score(X_dev, y_dev) # Calculate score  \n",
    "        print(\"penalty = %s, C = %8.3f, Score = %.4f\" % (penalty, C, score))\n",
    "    \n",
    "        # Check if better\n",
    "        if score > best_logistic_score:\n",
    "            best_logistic_params = {'C':C, 'penalty':penalty}\n",
    "            best_logistic_score = score\n",
    "        \n",
    "print(\"\\nNaive Bayes: best parameter: %s, score = %f\" % (str(best_bayes_params), best_bayes_score))\n",
    "print(\"Logistic Regression: best parameter: %s, score = %f\" % (str(best_logistic_params), best_logistic_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: f-score = 0.9870, accuracy = 0.9870\n",
      "Logistic Regression: f-score = 0.9950, accuracy = 0.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peiyuns/anaconda2/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Classifiers\n",
    "bayes_clf = MultinomialNB(alpha = best_bayes_params['alpha'])\n",
    "logistic_clf = LogisticRegression(C = best_logistic_params['C'], penalty = best_logistic_params['penalty'])\n",
    "\n",
    "# Train classifiers\n",
    "bayes_clf.fit(X_train, y_train)\n",
    "logistic_clf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Naive Bayes: f-score = %.4f, accuracy = %.4f\" % (f1_score(bayes_clf.predict(X_test),y_test, average = 'macro'), accuracy_score(bayes_clf.predict(X_test),y_test)))\n",
    "print (\"Logistic Regression: f-score = %.4f, accuracy = %.4f\" % (f1_score(logistic_clf.predict(X_test),y_test, average = 'macro'), accuracy_score(logistic_clf.predict(X_test),y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the classifier and vectorizer\n",
    "pickle.dump(logistic_clf, open(\"Logistic_{C0.1}_{l1}.pk1\", \"wb\"))  \n",
    "pickle.dump(vec, open(\"DictVectorizer.pk1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the classifier and vectorizer\n",
    "logistic_clf = pickle.load(open(\"Logistic_{C0.1}_{l1}.pk1\", \"rb\"))  \n",
    "vec = pickle.load(open(\"DictVectorizer.pk1\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
